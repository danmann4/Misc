{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0624e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file 'digit_model' is how we are going to generate our model to predict what numbers were fed in. \n",
    "# The next file 'image_process' will discern what is fed into this model.\n",
    "# import the necessary modules\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95ce817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow has a 70,000 digit MNIST dataset pre-built and cleaned available. \n",
    "# Load the data set and split as test/train 1:6 by default. \n",
    "# The images are already threshold cleaned, and 28x28 pixels\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe563db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images along the row axis\n",
    "train_images = tf.keras.utils.normalize(train_images, axis=1) \n",
    "test_images = tf.keras.utils.normalize(test_images, axis=1) \n",
    "print(test_images.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f582d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label: 5\n"
     ]
    }
   ],
   "source": [
    "# Plot the first train image for reference\n",
    "plt.imshow(train_images[0], cmap=\"gray\") \n",
    "plt.show() \n",
    "print(f'Image Label: {train_labels[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a61972",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now lets build a neural network and train it to the data. \n",
    "\n",
    "# A simple sequential model will do the trick since we are just using this for digit identification.\n",
    "# Using a Conv2D layer would likely improve our performance for image processing, but this scenario is not too demanding.  \n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Lets flatten out the input image into a 1D array first\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Now we can add some fully conected hidden layers. \n",
    "# I arbitrarely chose 128 nodes for the two hidden layers based on similar examples. \n",
    "# You could probably get away with a better structure if in-depth optimization was needed. \n",
    "# The important thing is that our final layers has an output of 10 for the unique digits. \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ced261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 897us/step - loss: 0.2577 - accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.1032 - accuracy: 0.9679\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 872us/step - loss: 0.0705 - accuracy: 0.9775\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 885us/step - loss: 0.0522 - accuracy: 0.9834\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 884us/step - loss: 0.0388 - accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21949ee0e08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets train the model. \n",
    "# Using categorical cross-entropy for our loss function, and going with \"adam\" to get an adaptive gradient descent optimzation.\n",
    "# Going with 5 epochs arbitarily as the performance turns out adequate.\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(x=train_images, y=train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dce7aa18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 596us/step - loss: 0.0928 - accuracy: 0.9729\n",
      "Model Accuracy: 0.9728999733924866\n"
     ]
    }
   ],
   "source": [
    "# Now lets feed the test images into the trained model and check our performance. \n",
    "# If we really wanted to peel back the performance we sould be including multiple metrics for comparison. \n",
    "# Another multi-class metric we could run is macro/micro F1-score. This would give us a hybrid between precision and recall.\n",
    "test_loss, test_accuracy = model.evaluate(x=test_images, y=test_labels)\n",
    "print(f'Model Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24f006f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can get the model's best prediction for each test image by choosing the highest output from that softmax output layer.\n",
    "predictions = model.predict([test_images]) \n",
    "pred_val = [np.argmax(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a1f17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just as a sanity check, here is a predicted output example.\n",
    "print(f'Test precision: {pred_val[0]}') # Print out the number\n",
    "plt.imshow(test_images[0], cmap=\"gray\") # Import the image\n",
    "plt.show() # Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76aa3b19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: digit_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Great, everything is working. Now we can save the model and use it for our images. \n",
    "model.save('digit_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
